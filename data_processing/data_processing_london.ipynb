{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3397c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Recherche d'un dataset Londres valide (avec prix et √©quipements)...\n",
      "üéØ TROUV√â ! Date : 2025-05-06\n",
      "üìä √âchantillon : 317/500 prix valides d√©tect√©s.\n",
      "‚è≥ T√©l√©chargement du dataset complet...\n",
      "‚úÖ Londres charg√© avec succ√®s : 61964 lignes sans NA sur le prix.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def find_working_london_dataset(max_months=12):\n",
    "    \"\"\"\n",
    "    Parcourt les archives d'Inside Airbnb pour trouver un dataset de Londres \n",
    "    valide et non vide.\n",
    "    \"\"\"\n",
    "    # On commence la recherche √† partir d'aujourd'hui\n",
    "    current_date = datetime.now().replace(day=1)\n",
    "    \n",
    "    print(\"üîç Recherche d'un dataset Londres valide (avec prix et √©quipements)...\")\n",
    "\n",
    "    for i in range(max_months):\n",
    "        # Format de date typique Inside Airbnb (souvent entre le 5 et le 15 du mois)\n",
    "        # On teste le 6 du mois, date fr√©quente de mise √† jour\n",
    "        date_str = current_date.strftime(\"%Y-%m-06\")\n",
    "        url = f\"http://data.insideairbnb.com/united-kingdom/england/london/{date_str}/data/listings.csv.gz\"\n",
    "        \n",
    "        try:\n",
    "            # 1. V√©rification de l'existence du fichier (HEAD)\n",
    "            resp = requests.head(url, timeout=5)\n",
    "            if resp.status_code == 200:\n",
    "                # 2. Chargement d'un √©chantillon pour v√©rifier le contenu\n",
    "                # On charge 500 lignes pour √™tre s√ªr d'avoir un √©chantillon repr√©sentatif\n",
    "                df_test = pd.read_csv(url, nrows=500, compression='gzip', low_memory=False)\n",
    "                \n",
    "                # 3. V√©rification des colonnes et des donn√©es NA\n",
    "                has_cols = 'price' in df_test.columns and 'amenities' in df_test.columns\n",
    "                \n",
    "                if has_cols:\n",
    "                    # V√©rification que les prix ne sont pas TOUS de type NA\n",
    "                    # On compte les valeurs non-nulles\n",
    "                    valid_prices = df_test['price'].notna().sum()\n",
    "                    \n",
    "                    if valid_prices > 0:\n",
    "                        print(f\"üéØ TROUV√â ! Date : {date_str}\")\n",
    "                        print(f\"üìä √âchantillon : {valid_prices}/500 prix valides d√©tect√©s.\")\n",
    "                        return url\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è Date {date_str} ignor√©e : La colonne 'price' est vide (que des NA).\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Date {date_str} ignor√©e : Colonnes manquantes.\")\n",
    "            \n",
    "        except Exception:\n",
    "            pass # On continue si l'URL exacte n'existe pas\n",
    "        \n",
    "        # On recule d'un mois pour l'it√©ration suivante\n",
    "        current_date = (current_date - timedelta(days=1)).replace(day=1)\n",
    "\n",
    "    return None\n",
    "\n",
    "# ==============================================================================\n",
    "# EX√âCUTION & CHARGEMENT\n",
    "# ==============================================================================\n",
    "london_url = find_working_london_dataset()\n",
    "\n",
    "if london_url:\n",
    "    # On ne charge que les colonnes n√©cessaires pour √©conomiser la RAM\n",
    "    cols_to_keep = ['id', 'amenities', 'price', 'latitude', 'longitude', \n",
    "                    'property_type', 'room_type', 'accommodates', 'bedrooms', \n",
    "                    'beds', 'bathrooms_text', 'neighbourhood_cleansed']\n",
    "    \n",
    "    print(\"‚è≥ T√©l√©chargement du dataset complet...\")\n",
    "    df_london_raw = pd.read_csv(london_url, usecols=cols_to_keep, compression='gzip', low_memory=False)\n",
    "    \n",
    "    # Nettoyage imm√©diat des lignes o√π le prix est NA (pour √™tre 100% s√ªr)\n",
    "    df_london_raw = df_london_raw.dropna(subset=['price'])\n",
    "    \n",
    "    print(f\"‚úÖ Londres charg√© avec succ√®s : {len(df_london_raw)} lignes sans NA sur le prix.\")\n",
    "else:\n",
    "    print(\"‚ùå Impossible de trouver un dataset valide automatiquement.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envproject (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
